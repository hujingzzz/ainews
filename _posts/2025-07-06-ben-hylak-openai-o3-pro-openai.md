---
layout: post
title: Ben Hylak's unique evaluation of OpenAI's latest o3pro model OpenAI's walking the path of "Intensive Learning Vertically"
date: 2025-07-06 12:00:00 +0800
category: Frontier Trends
thumbnail: /style/image/ben-hylak-openai-o3-pro-openai_1.jpg
icon: code
---
* content
{:toc}

Ben Hylak's unique assessment of OpenAI's latest o3pro model

Positioning # o3Pro: Task-level SuperRisk Assistant

- **Task-specific models**: different from routine chat models (e.g. GPT-3.5, GPT-4o);

- o3 Pro is designed as:  for complex tasks, deep analysis, highly rational, calm, non-dialogued, more like an "executor analyst" or "strategist"

# Evaluation method: with traditional benchmark unable to assess ** Author's assessment strategy:**

- Non-dialogue testing;

- Build a “real business scene” + a “complete context”;

- Observe its** ability to address complex tasks and the quality of output of specific implementation recommendations**.

# # assessment example: corporate strategic planning mission

- Author of Rainrop: all planning meeting records;

- Long-term/short-term objectives;

- Voice memorandum;

- Team history.

Unified feed to o3 Pro, proposing: “Please give the next phase of the business strategic plan.” ** Output: **

- o3 Pro gives: precise target indicators (target metrics);

- A clear time line (timelines);

- Strict priority (priority);

- Items proposed for deletion (cut list);

The high quality of the output** prompted the team to change its strategic direction**.

# o3 Pro's summary of key strengths **1.  High level of intelligence, but need to ** Feed context **

- Is not suitable for short prompt tests;

- The need for “many background + clear objectives” for performance;

- Not necessarily for casual chats.

**2. Strong environmental perception and tool interaction**

- Be able to judge whether ** or not external tools are required**;

- Not to fabricate unaccessible information, but to give a clear indication of the need for “you tell it”;

- Very good at dispatching, using external functions, API, database, etc.

**3.  System alerts and context are extremely important**

- **system prompt** has far-reaching implications for their conduct;

- For example, "You're a product manager" vs. "You're a safety expert" will produce a very different style and strategy.

**4. Potential weaknesses: easy to over-analyse in low context**

- Inadequate contextualization can lead to “excessive thinking” and can easily fall into the dead end of reasoning;

- “Direct action type” tasks (e.g. SQL queries) may not be as flexible as basic models.

# Model comparison: different from the same model! [] (https://assets-v2.Circle.so/ k0oefebl4utvowv1p19jp80dmyid) #OpenAI is walking the path of "enhanced learning"

- OpenAI not only teaches the model "How to Call Tools" but also "When to Call Tools";

- The advancement of LLM, which is one of the key routes for determining the timing of the use of tools, as is the case with humans,** common artificial intelligence;

- O3 Pro is the product of this strategy.

# Use of Recommendations and Best Practices

# Use the hint to suggest: **Context is king**:

- Relevant documents, targets, role descriptions should be included in the reminder;

- Like, " Feed cookies to cookie biscuits."

** Clear objectives**:

- Do not say "let me write something" but say "let me write a three-phase product online strategy based on the following data".

**Enhanced system hint**:

- Role setting in system alerts and mission statements have a significant impact on the model's “behavior style”.

# Summing up **O3Pro is not your "chat" friend, he's your company's top-level strategic analyst with no bullshit.** The following is the full Chinese translation** of the article ** God is hungry for Context: First thoughts on o3 pro**:

## # God yearned for context: ** The opening impression for o3-Pro** ($20/$80). This supports an unverified community theory, the pro-transformation is the 10 times the underlying model, as stated by the leak, that OpenAI today revised the pricing of O3 **80% (from $10/$40 per million token to $2/$8 - equal to GPT-4!) **O3-Pro**, paving the way for the roll-out of O3-Pro** ($20/$80). **Ben Hylak, which supports an unverified community theory, the pro-transformation is the 10 times the basic model, and uses most voting mechanisms (the mechanism is mentioned in OpenAI and in our Chai programme) **3-Pro-ince of human testing **64% to beat o3, and slightly beat 4 business benchmark tests ($20/$80).

# The key I found was: **Don't "talk" to it. To use it as a **report generator**: give it enough context, define the target, then let it produce the results. That's how I'm using the o3. But it also raises the problem of assessing the o3 pro.

I and my co-founder, Alexis, spent time collating all our past planning minutes, targets, and even voice memos in Rainrop, and then allowing O3-Pro to take this information to work out a plan. We were shocked. It generated the kind of concrete plan and analysis that I've always wanted LLM to export ** -- including target indicators, timetables, priorities, and clearly indicating which ones we've lost.

The real challenge is to ** integrate them into society**. Like a very high 12-year-old IQ to go to college. Smart is smart, but not a good employee if you can't adapt to society.

# Today's "integration" depends mainly on tools:

- The ability of models to collaborate with humans, external data, and other AIs;

- It is an excellent “thinker”, but it also needs to grow into an excellent “executor”.

O3 Pro really jumped into this:

- Be demonstrably better able to understand the environment in which they live;

- Accurate expression of the tools available to them;

- Knowing when to ask for information from the outside world (rather than pretending to know);

- Can choose the right tools to do the job.

##O3 pro (left) vs. o3 (right): The o3pro on the left is clearly stronger in understanding its environment.[https://assets-v2.circle.so/q9mkubstrvot607cpygfk3er] ## from early use: If you don't give it enough context, it has a tendency to ** overthink**. It is good at analysing, working with tools, but ** not very good at doing it directly**. I think it is an excellent “organizer.” For example, some ClickHouse SQL problems, o3 do better than o3 Pro. The results may vary from person to person. [https://assets-v2.circle.so/fwq5yja3sl3sj14n236vk7pxeg) ####o3

- Claude Opus looked "very strong," but never showed me evidence of it.

- O3 Pro's output is better,** it's a completely different dimension**.

##OpenAI is deeply advancing the path of vertically reinforced learning (e.g. Deep Research, Codex): teaching not only how to use tools, but also when to use tools**.

## How to suggest the reasoning model has not changed: My o1 reminder guide is still valid. The context is everything – it's like feeding cookies to Cookie Monster. It's a way to start the LLM memory, and it's targeted, making it more effective.

# Other fragmentary observations:

- The impact of system alerts on model behaviour is significant (positive change);

- significant differences between o3 Pro and o3;

- The difference between Claude and Gemini;

- OpenAI's “tool-enhanced reasoning” strategy is indeed ahead.

Original language: https://www.latet.space/p/o3-pro