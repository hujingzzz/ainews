---
layout: post
title: Deepmind introduces a new generation of robot AI models that can run independently on the robot's body without relying on clouds to calculate resources.
date: 2025-07-04 12:00:00 +0800
category: Frontier Trends
thumbnail: /style/image/deepmind-ai_1.jpg
icon: game
---
* content
{:toc}

Deepmind introduces a new generation of Gemini Robotics On-Device robot AI models that can ** run independently on robotics** without relying on cloud-based computing resources. The model combines visual, linguistic understanding and movement decision-making capabilities to perform highly intelligent and variable practical tasks. ** It addresses core issues: **

- ** Reduced reliance on cloud computing** Reduced delay and increased response speed.

- ** Operation in an unstable network environment** improves reliability.

- ** Achieving universal operating capability and rapid adaptation to new tasks**  Improving robotic interoperability.

** Gemini Robotics robotic model ** first launched in March 2025, introducing the operational reasoning of the physical world based on the Gemini model, combining vision, language and movement (VLA).[!] (https://assets-v2.circle.so/0p2ci3src0jg5k3qdfecah25nkhn) # Model capacity: What can it do? [https://assets-v2.circle.so/dgiokn48zb7b75r6y954a4prehh) # Technical characteristics # 1.

- The model performed ** calculation of resource compression optimization** to enable it to operate on robotic equipment with a capacity limit.

- GPU servers, CPUs or small AI chips are not required to support reasoning.

2. Multimodel integration capability

- Gemini 2.0 model structure based on DeepMind, which combines visual, linguistic and behavioural control.

- Integration capability of ** image perception + command understanding + action execution **.

3. Few-shot fine-tuning mechanism

- Support for the adaptation of new tasks under very few samples (50-100 demonstrations only), which significantly reduces the threshold for development and deployment.

# How's it going? # In many tests, it's better than the existing model:

- ** Higher mission completion rate**: In particular for tasks not previously seen or in new environments, the model displays a stronger generalization capability.[https://assets-v2.circle.so/gfm4bayqbl47ft4fk5i6114p8u2n2] - ** Directive follows:** Directives: ** Better than other local alternatives in more challenging extra-distributive tasks and complex multi-step instructions.  (https://assets-v2.circle.so/zaxjzqrcht2tv6j648oiajud96j2) - ** Response is faster: Benefit from local operations without having to wait for cloud returns.

- ** More stable implementation**: high levels of consistency can also be maintained on different robotic platforms.

** Example of experimental mission: ** [] (https://assets-v2.circle.so/mjbfvr6hf0e52znqr5wee7ngr3b0) ##appropriate: not only operational, but also cross-platform

- After training on the ALOHA platform, migration to: **Franka FR3 two-arm robot**: completion of industrial level assembly tasks.

- **Apollo Emulator**: Operation of natural language in family/service-type environments.

Note: This cross-platform migration** does not require a re-training model** and the same intelligence capability can be used only with minor adjustments.[https://assets-v2.circle.so/dfl0wl73hm3c5nr9330vnj0zcva] ## Developer support: # How to participate in and use?[] (https://assets-v2.circle.so/pgc6wk4pzcdxm0qj7v157acafof3] Mujo Coco Gemini Robotics SDK Gemini Robotics tech report ** Gemini Robotics On-Device marks the new stage of robot AI's “available”, “can be deployed”, “can be generalized”**.

-  Persistence of peripheral intelligence**: robots can think independently, perform tasks and no longer rely on external servers.

-  Reduced deployment costs**: Adaptive + rapid fine-tuning  Lower industry application thresholds.

- ** Uniform cross-hardware model structure**: a robotic device with models adapted to various forms can be achieved in the future.

Official presentation: https://deepmind.google/discover/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/