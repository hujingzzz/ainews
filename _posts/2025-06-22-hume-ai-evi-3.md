---
layout: post
title: Hume AI Release EVI 3-You can understand your voice and interact with you in the voice and style you like.
date: 2025-06-22 12:00:00 +0800
category: Frontier Trends
thumbnail: /style/image/hume-ai-evi-3_1.jpg
icon: lock
---
* content
{:toc}

Hume AI ♪ Working to create the one ♪**The voice of emotional comprehension. AI**The voice of emotional comprehension. AI They're setting a goal.-**Present. 2025 End of year Provides a completely personal voice.AIExperience**Present. 2025 End of year Provides a completely personal voice.AIExperienceI don't know.EVI 3 It's their third generation.“At the end of the day,Voice-LanguagesIt's not a good idea, it's not a good idea.Large model It doesn't just listen.Yes. It's better to express and understand emotions. It's looking to the future.“At the end of the day,Emotional.AIInteractiveIt's not a good idea, it's not a good idea.Key milestonesI don't know.
EVI 3 It's an ability.“At the end of the day,You know what you're saying?I'm talking to you with emotion.It's not a good idea, it's not a good idea.It's... it's... it's...AIAssistant You can understand your voice and interact with you in the voice and style you like.I don't know.
**What's the main function?**What's the main function?

- Speak like a man and respond to you. ♪ Including with pleasure ♪Angry.Shy.Weary and so on.30Multi-linguistic ethosI don't know.

- I can still hear the emotions in your voice. Make it natural.There's a common response.I don't know.

- You can set it.AISound style Like what?“At the end of the day,Talk like a pirate.I'm not sure what I'm going to do.Or...“At the end of the day,Gently whispering.

- The conversation isn't Caden. It's almost as natural as real people talk.I don't know.

**What did it solve?**What did it solve?

- Traditional voice assistants only.“At the end of the day,It's a copy of the book.I'm not sure what I'm going to do.I don't understand your emotions.I don't know.

- It's...“At the end of the day,Just talking and thinking.It's not a good idea, it's not a good idea.Mechanisms Let it speak while it can. Search side by side.Rationale. It's not just a single question-and-answer robot anymore.I don't know.

- EVI 3 Will“At the end of the day,SoundIt's not a good idea, it's not a good idea.Turned into a real temperature interface. Closer to the human mode of communication.I don't know.


## EVI 3 Core characteristics

### 1. Integrated voice-Language structureSpeech-Language ArchitectureI'm not sure what I'm talking about.

- **Unified model for voice input and output**Unified model for voice input and output-It's not like tradition.TTSText to VoiceI'm not sure what I'm talking about.orASRVoice recognitionI'm not sure what I'm talking about.It's separated. EVI 3 Use one**Self-regression models**Self-regression modelsHandle text at the same timeTI'm not sure what I'm talking about.And voice.VI'm not sure what I'm talking about.tokenI don't know.

- **System reminder structureSystem PromptI'm not sure what I'm talking about.**System reminder structureSystem PromptI'm not sure what I'm talking about.-Include language and voicetoken Not only define interactive content Controls the tone, too.Behavior behavior, style, etc.I don't know.

### 2. Emotional and style personality expression

- EVI 3 Any sound can be generated by a hint ♪ And give it special ♪“At the end of the day,CharacterIt's not a good idea, it's not a good idea.or“At the end of the day,Emotional style

- Support **Super30It's a complicated voice style.**Super30It's a complicated voice style.-Like“At the end of the day,It's exciting.I'm sorry, I'm sorry, I'm sorry, I'm sorry.Pretending to be tired.I'm sorry, I'm sorry, I'm sorry, I'm sorry.Pirates.It's not a good idea, it's not a good idea.Wait.I don't know.

- You can create it with a hint. AI It's... it's... it's...“At the end of the day,SoundIt's not a good idea, it's not a good idea.and“At the end of the day,CharacterI'm not sure what I'm going to do.It's kind of soft.Humor.Professional categoryI don't know.There's already more than that.10Ten thousand custom voices are generated on the platform. It's much more flexible than a voice helper with a fixed role.I don't know.

- andGPT-4oCompared to the model Yes.**It's more natural to express real feelings and tone changes.**It's more natural to express real feelings and tone changes.I don't know.

### 3. Efficient voice response capability

- Achieved **Below300msThe model's reasoning is delayed.**Below300msThe model's reasoning is delayed.I don't know.

- In practical application EVI 3 The response time is in the USS deployment environment. **0.9-1.4s**0.9-1.4s Better than GPT-4o2.6sI'm not sure what I'm talking about.and Gemini1.5sI'm sorry, I don't know.

### 4. Emotional recognitionVoice Emotion UnderstandingI'm not sure what I'm talking about.

- Support the recognition of emotions from the voice.——No text required Only the tone.Rhythm and sound featuresI don't know.

- It's under evaluation. EVI 3 It's accurate. **9A basic emotion.**9A basic emotion. Yes.8Better than GPT-4o It's more natural.I don't know.

### 5. Real-time multitask capability(")Just talking and thinking.It's not like it's going to happen.

- Support the insertion of new context in voice outputtoken **Synchronize searchRationale.Tools Use**Synchronize searchRationale.Tools UseI don't know.

- Achieve similar“At the end of the day,System ParallelIt's not a good idea, it's not a good idea.Intelligent Response Mechanisms Jean.AIIn the conversation, speak like a human being.“At the end of the day,Thinking.

EVI 3 It's possible, depending on the context.**Automatically adjust tone**Automatically adjust tone Yeah.**Clear control style by hint**Clear control style by hintI don't know.Like what?-

- **Stutter when you're anxious.**Stutter when you're anxious.stammers anxiouslyI'm not sure what I'm talking about.

- **There's a lot of debate going on.**There's a lot of debate going on.debates enthusiasticallyI'm not sure what I'm talking about.

- **Softly speaking in private conversation.**Softly speaking in private conversation.whispers intimatelyI'm not sure what I'm talking about.

It makes it look like it's communicating with the user.**It's real.Naturally.It's emotional.**It's real.Naturally.It's emotional. It's no longer a single voice output.I don't know.
The user only needs a hint. EVI 3 It's fine.**In less than a second.**In less than a second.Generate a brand-new sound and personality set.-

- “At the end of the day,An Australian historical lover with a dumb voice.I'm not sure what I'm talking about.raspy Australian history buffI'm not sure what I'm talking about.

- “At the end of the day,A well-spoken English prank.I'm not sure what I'm talking about.sassy British pranksterI'm not sure what I'm talking about.

- “At the end of the day,An exciting Caribbean musician.I'm not sure what I'm talking about.excited Caribbean musicianI'm not sure what I'm talking about.

That's why... AI He's no longer a voice assistant with a fixed template. ♪ And become ♪**Altitude CustomableVariated virtual role engine**Altitude CustomableVariated virtual role engine Useable for gamesVideoEducationVarious applications such as virtual assistantsI don't know.

## EVI 3 Innovative and training approaches

### 1. **Unified voice-Language model architectureSpeech-Language Token IntegrationI'm not sure what I'm talking about.**Unified voice-Language model architectureSpeech-Language Token IntegrationI'm not sure what I'm talking about.
**✅ Innovation point-**✅ Innovation point-
EVI 3 Model voice and text messages Not voice recognition like the traditional system.ASR.Language processingNLPI'm not sure what I'm talking about.And Text SynthesisTTSI'm not sure what I'm talking about.Separate treatmentI don't know.
**🔧 Technical principles-**🔧 Technical principles-
Use one **Self-regression modelsAutoregressive ModelI'm not sure what I'm talking about.**Self-regression modelsAutoregressive ModelI'm not sure what I'm talking about. Deal with two types of input-Text tokenTI'm not sure what I'm talking about.And voice. tokenVI'm sorry, I don't know.
These. token ♪ Be combined into one ♪**“At the end of the day,System HintsI'm not sure what I'm talking about.system promptI'm not sure what I'm talking about.**“At the end of the day,System HintsI'm not sure what I'm talking about.system promptI'm not sure what I'm talking about. Provides not only language context It also defines voice style.Words and rhythmsI don't know.
Yeah.**Listen and understand.♪ Talking and generating ♪**Listen and understand.♪ Talking and generating ♪ To form a natural voice flowI don't know.
![](https://assets-v2.circle.so/gnyioasvze7lu5eouwm7drhrtvcu)**📈 Advantages-**📈 Advantages-
Information flows smoothly between different patterns It's more natural to react.I don't know.
Models are easier to capture.“At the end of the day,The way you talk.It's not a good idea, it's not a good idea.Emotions in the middle.Styles and rhythms, et cetera.I don't know.

### 2. **Training strategy for personalized expression**Training strategy for personalized expression
**✅ Objective-**✅ Objective-
Achieved AI Do not use only presets“At the end of the day,SoundI'm not sure what I'm going to do.It's real-time. It's real-time.**A variety of voice styles and personality features.**A variety of voice styles and personality features.I don't know.
**🔬 Methodology-**🔬 Methodology-

- Large-scale multi-talker data modelling-Not to fine-tune each sound. It's training a model to spread all possible human voices.I don't know.

- Use label style/Emotional Data Set Help Model Society“At the end of the day,How to express anger.Happy.Shy.It's not a good idea, it's not a good idea.Wait for the tone.I don't know.

- Real-time reconciliation of speech generation parameters during reasoning Change instantaneously according to the hintI don't know.

### 3. **Enhanced learning to optimize output quality**Enhanced learning to optimize output quality
**🎯 Problem-**🎯 Problem-
How to get model output voice performance closer to user preferences Like what?“At the end of the day,You have to be softer and softer.It's like, "I don't know."Don't be too mechanical.What's the matter with you?
**🧠 Solutions-**🧠 Solutions-

- Introduction **Enhanced learningReinforcement Learning, RLI'm not sure what I'm talking about.**Enhanced learningReinforcement Learning, RLI'm not sure what I'm talking about. Technology The goal is to optimize the model.**Expression effect and user feedback match**Expression effect and user feedback matchI don't know.

- On the basis of user-model interaction Models learn which voice output styles score high.Considered“At the end of the day,That's nice.Naturally.Emotional.

**🏆 Effect-**🏆 Effect-

- Make the model autonomous.“At the end of the day,Adjusting your way of speaking.I'm not sure what I'm going to do.It's getting closer to what humans like to sound.I don't know.

### 4. **Fluid voice generation mechanismStreaming Voice-to-Voice ProcessingI'm not sure what I'm talking about.**Fluid voice generation mechanismStreaming Voice-to-Voice ProcessingI'm not sure what I'm talking about.
**🔧 Technology challenges-**🔧 Technology challenges-
The traditional voice generation is...“At the end of the day,Let's hear it.I'm not sure what I'm going to do.It's a delay.IncoherentI don't know.
**✨ Solutions-**✨ Solutions-

- EVI 3 Achieved.**Fluid processingStreaming GenerationI'm not sure what I'm talking about.**Fluid processingStreaming GenerationI'm not sure what I'm talking about. It can be dynamically adjusted to generate content during the conversation.I don't know.

- Support the injection of new context during voice output Like when the user is asking questions. AI It can be done in real time.**SearchRationale.Call Tool**SearchRationale.Call ToolWait.I don't know.

**🧩 Model Mechanism DiagramsDocumentation:**🧩 Model Mechanism DiagramsDocumentation:
A uniform model continues to receive input.Voice + Text tokenThis is the first time I've ever seen you.When generating a voice response You can insert it.“At the end of the day,Search ResultsI'm sorry, I'm sorry, I'm sorry, I'm sorry.Tool Call FeedbackIt's not a good idea, it's not a good idea.Waiting Real-time integration into the response.I don't know.

### 5. **Efficient delayed control and deployment optimization**Efficient delayed control and deployment optimization
**🚀 Optimize direction-**🚀 Optimize direction-
EVI 3 The goal is to provide a dialogue experience close to humanity. That's why we have to do it.**Low-delay voice interaction**Low-delay voice interactionI don't know.
**⚙️ Method of implementation-**⚙️ Method of implementation-

- Through optimization of model architecture and deployment modalities Makes the voice respond.**Below 300 milliseconds**Below 300 milliseconds;

- For the user. Overall response timeIncluding the Internet.I'm not sure what I'm talking about.Control in**1.2 Within seconds**1.2 Within seconds By comparison GPT-4o and Gemini Faster.I don't know.

**✅ Summary-EVI 3 Five breakthroughs in research methods.**✅ Summary-EVI 3 Five breakthroughs in research methods.
![](https://assets-v2.circle.so/anaqwe7orethvlwm5mxi8i6xi78y)
## EVI 3 Model assessment results

### 🧩 1. Evaluation of the overall dialogue experienceOverall Conversational PreferenceI'm not sure what I'm talking about.
**✔ Test Method-**✔ Test Method-

- Blinding methods-The user doesn't know which model to use.I don't know.

- By each user and model 1–3 Minutes of free dialogue Task“At the end of the day,Jean. AI Tell me something interesting.

- User scores the model from seven dimensions.I don't know.

**📐 Assess dimensions-**📐 Assess dimensions-

- AmusementInteresting.I'm not sure what I'm talking about.

- Audio qualityAudio QualityI'm not sure what I'm talking about.

- EmpathyCompassion.I'm not sure what I'm talking about.

- ExpressivenessExpression abilityI'm not sure what I'm talking about.

- Interruption handlingInterrupt processI'm not sure what I'm talking about.

- NaturalnessNatureI'm not sure what I'm talking about.

- Response speedResponse SpeedI'm not sure what I'm talking about.

**🏆 Outcome-**🏆 Outcome-
**EVI 3 Better than all seven dimensions. GPT-4o Highest overall preference ratingI don't know.**EVI 3 Better than all seven dimensions. GPT-4o Highest overall preference ratingI don't know.
![](https://assets-v2.circle.so/u8skki0xtk5k7w1nqls9aajsjqr6)
### 🎭 2. Assessment of emotional and style expression abilitiesEmotion and Style ModulationI'm not sure what I'm talking about.
**✔ Test Method-**✔ Test Method-

- Participants are asked to let models express themselves. **30 A specific tone or style**30 A specific tone or styleFor example...“At the end of the day,Angry.I'm sorry, I'm sorry, I'm sorry, I'm sorry.Excitement.I'm sorry, I'm sorry, I'm sorry, I'm sorry.Pirates.I'm sorry, I'm sorry, I'm sorry, I'm sorry.Keep your voice down.It's not a good idea, it's not a good idea.Wait.I'm sorry, I don't know.

- Compare Object-EVI 3GPT-4oGeminiSesameI don't know.

- Users express the sentiment to the model after each conversation./Rating of style accuracy1–5minI'm sorry, I don't know.

**🧪 Example style-**🧪 Example style-
Each participant was asked to use each model to speak with a particular emotion or style in the table below.-I'm afraid.Angry.Anxieties.Boring.Toon.Shame.Disillusioned.Firm.It's embarrassing.Excited.Tired.Loud.Scared.Pain.It's like seeing a cute little dog.It's like everything.It's like watching a painting.It's like running a marathon.Keep your voice down.SingleI can't take it anymore.Rotten.PiratesPride.Sad.It's ironic.Heat.WhisperingShout! Shout!I don't know.
**🏆 Outcome-**🏆 Outcome-
**EVI 3 The average score was significantly higher. GPT-4oGemini and Sesame Show me the strongest tone./The ability to express emotional change.I don't know.**EVI 3 The average score was significantly higher. GPT-4oGemini and Sesame Show me the strongest tone./The ability to express emotional change.I don't know.
![](https://assets-v2.circle.so/8vhocltpmocrl7rfix2mnu1v680z)
### 🎧 3. Emotional recognition capability assessmentEmotion UnderstandingI'm not sure what I'm talking about.
**✔ Test Method-**✔ Test Method-

- All users say the same thing.Like_Other OrganiserCan you hear the mood in my voice?I don't know what to do.But it's expressed in different emotions.I don't know.

- Models have to recognize voice. It's not about text.I don't know.

- Compare the model to the following. 9 The ability to recognize emotions.I don't know.

**🧪 Emotion type-**🧪 Emotion type-
AfraidAmusedAngryDisgustedDistressedExcitedJoyfulSadSurprised
**🎯 Rating criteria-**🎯 Rating criteria-

- Models recognize emotional accuracy.1–5minI'm not sure what I'm talking about.

- Nature of model response1–5minI'm not sure what I'm talking about.

**🏆 Outcome-**🏆 Outcome-
**EVI 3 Yes. 9 There's an emotion. 8 Item Identification Accuracy is higher than GPT-4o It's also better at responding to nature.I don't know.**EVI 3 Yes. 9 There's an emotion. 8 Item Identification Accuracy is higher than GPT-4o It's also better at responding to nature.I don't know.
![](https://assets-v2.circle.so/q1d3a1f0nbvzq2bpmecbr3x2xaw9)
### ⏱️ 4. Delayed assessment of actual responsePractical Latency TestI'm not sure what I'm talking about.
**✔ Test Method-**✔ Test Method-
After the user's conversation, AI The time between the start of the responseDelays in dialogueThis is the first time I've ever seen you.Tested in New York. The server's in Missy.I don't know.
![](https://assets-v2.circle.so/j75pfal4j4afr2kfjwivzi4iyb7o)**🏆 Summary-**🏆 Summary-
**EVI 3 Quick response. Visible superior to GPT-4o Close. Sesame Quicker Than Gemini**EVI 3 Quick response. Visible superior to GPT-4o Close. Sesame Quicker Than Gemini Fits for real-time voice dialogue scenesI don't know.
Official presentation-https://www.hume.ai/blog/introducing-evi-3 
Online experience-demo.hume.ai
