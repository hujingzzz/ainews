---
layout: post
title: 11Labs Launched Eleven v3 (Alpha Version) - The most powerful text-to-speech model ever-"Not only speak, but act."
date: 2025-06-25 12:00:00 +0800
category: Frontier Trends
thumbnail: /style/image/11labs-eleven-v3-alpha_1.jpg
icon: link
---
* content
{:toc}

* current {:toc} ElevenLabs has launched a new generation of text-to-language models **Eleven v3 (Alpha version)**, which is one of the most powerful TTS models at present, supporting a natural dialogue between more than 70 languages, multiple actors, and controlling voice and non-verbal expression through the precision of audio labels such as [sad], [whospers], [lughs]. v3 has a stronger text-reading capability that simulates interruptions, emotional changes and tone adjustments in real conversations. This makes it very suitable for video creation, audio book production and media tool development. ** Features: **

- Support **70+ Language**

- Support ** Multi-Role Dialogue**

- Support** audio tags** (e.g. [sad], [lughs], [whisters] etc.) to control emotions and performance

-V3 is a research preview, requiring a higher level of alert work, but it's very good at generating it.

- The new architecture has a deeper understanding of the text and allows for a more expressive voice

- Simulation of emotions, interruptions, tone changes in the reality dialogue**

- I'm about to open the API interface to support creators and developers

#  V3 main upgrade highlights

## 1. ** Emotion + Command + Sound  More True** v3 Supports the new '**audio tags'**, where developers or creators can control voice:

- Emotions. (Anger, happy, nervous, calm, etc.)

- Emphasis and tone.

- Pauses, speeds, mixes of sound (e.g. laughter, screams)

Example: You can generate a piece that moves from a "low voice" to a "hysteric laugh" and adds a background sound that allows the listener to immerse in it.

# 2. ** Multi-player, cross-interruptment of dialogue**

- Support for natural interactions ** two or more roles**;

- Support for **synchronous context and emotional matching**;

- Interruption, talk-making, humor, etc., can be set up in the dialogue;

- Simulation of real human dialogue scenes that are more fluid than any previous version.

## 3. ** Language coverage: 70+ Language support** 29 languages compared to v2, **v3 currently supports more than 70 languages**, over:

- All mainstream languages (English, Chinese, French, Spanish, Arabic, etc.)

- Small regional languages (Sanjaro, Kyrgyz, Urdu, etc.)

Use: Non-English podcasts, global sounding, localised audio content generation.[3] (https://assets-v2.Circle.so/oip0q3rh4t0m30zen48zsw7btzj4) ## 4. ** Text to Dialogue New Mode** This is one of the most powerful capabilities of v3:

- Automatically woven different roles, tone and sound into "dialogue audio" through plain text;

- Without the need to mark the role or tone of each sentence, the system will automatically judge;

- The dialogue generated is extremely active and consistent and applies to audio dramas, game dialogue, advertising, etc.

# v2 compared to v3![] (https://assets-v2.Circle. so/ o6z3wxmbc7u7e8ysxwhy9bzkn24) ##** Which labels are supported?**

- Emotions: [ANGRY], [LAUGHS], [WHISPERS]

- Action class: [SHUTING], [SIGHING]

- Sound class: [EVIL LAUGH], [GIGGLE] Label detail: Promising Guide

Official presentation: https://elevenlabs.io/v3