---
layout: post
title: OpenAudio, the latest voice-generated model-S1 claims to be pro-sounding and natural.
date: 2025-06-25 12:00:00 +0800
category: Frontier Trends
thumbnail: /style/image/openaudio-s1_1.jpg
icon: design
---
* content
{:toc}

OpenAudio announces the release of the latest speech-generation model - **S1 model**, with the goal of ** achieving the performance and nature of professional voice players**. The model was developed by the Hanabi AI research laboratory and released through the product platform ** Fish Audio**. S1 has:

- High natural, fluid sound.

- A rich tone and emotional control.

- Strong command follower

Its training data exceed **2 million hours of audio** and model parameters amount to **4 billion (S1)**, a landmark product. ** Model version**![] (https://assets-v2.Circle.so/mn0l9us6san94gdshu33xfjpe2us) both support the full functionality of emotions, tone labels, synthesis control, etc. The difference is mainly due to the balance of quality and performance.

## Main functional features! [https://assets-v2.Circle.so/tmn0pikgdjqw84n0bptwsipps82] ## Maximum bright spots: The greatest innovation of “playing” S1 like an actor is that it can understand and perform “** the emotions and tone of the person who speaks**”, just like a professional voicewriter. ** ** How did it work?** OpenAudio first trained a self-researched **student **STT (STT)** that automatically recognizes voice:

- Emotions (e.g. grief, anger, joy, common sense, sarcasm, etc.)

- Voice (e.g. rush, whisper, shout, scream, etc.)

- Talker's character information.

** Supported voice control tags: **[**] (https://assets-v2.circle.so/2j383de2jg7tqv6dsoa02nifzo5u) S1 has the most outstanding capability of its **rich voice expression control tags**, including: 1. Emotion Markers: e. g. (sad) (sar) (sarcast) (sarcastic) (empathetic) 2.

English, Chinese, Japanese, German, French, Spanish

- Korean, Arabic, Russian, Dutch, Italian, Polish, Portuguese

# How to achieve high quality? S1 high performance from the following key design: **Data and training strategy:**

- **2 million hours of audio data** (one of the largest industries)

- Self-research **reward model** used to optimize performance

- **Intensible online learning RLHF (using GRPO algorithms)**: used to fine-tune models to enhance sound authenticity and hearing quality

# # The model structure and reasoning optimizes #

- Structure: based on Qwen3 multi-model architecture, supporting future expansion to audio question and answer, text and voice recognition tasks (currently only TTS functionality is open)

- Audio decoding: Self-research Descripto Audio Codec system + Transformer structure

- Optimizing technology: Optimizing voice performance using online RLHF for enhanced learning (based on GRPO strategy)

##**  Global leader in multiple indicators: **[] (https://assets-v2.circle.so/7zmgi0hwrprli2xab50oki71ta5) - Huging Face TTS-Arena-V2 ranking 1 (human subjective rating)

- Word Error Rate: **0.008**, far better than industry models

- Character Error Rate (word error rate): **0.004**

- A very low level of pseudo-verbals, miswords, misrepresentations, common TTS problems.

S1 (https://assets-v2.circle.so/wmdrgycb38ykikg36wh5u83d5fri) even exceeds the existing model across the board in terms of voice expression, voice clarity, speech consistency.

# Very low price, available to all S1 is the most high-quality TTS model in the current market:

- **$15/million bytes only**

- Corresponds to approximately **$0.8 hours** audio costs

- significantly below the market mainstream (e.g. ElevenLabs, PlayHT, etc.)

Developmenters of [https://assets-v2.circle.so/wveop82lo8wc01cx45m4dl6myg3q) can deploy large-scale voice applications at very low cost, including passenger robots, podcast generation, AI role mix, etc.

You can experience the voice effects of the model online through OpenAudio **FishAudio Playground** (TTS currently available only and will support STT, TextQA, AudioQA, etc.). https://openaudio.com on FishAudio Playground