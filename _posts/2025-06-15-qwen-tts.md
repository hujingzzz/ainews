---
layout: post
title: Aliun release Qwen-TTS Text synthesis model Close to real voice. Support MandarinEnglish And three local Chinese dialects.
date: 2025-06-15 12:00:00 +0800
category: Frontier Trends
thumbnail: /style/image/qwen-tts_1.jpg
icon: code
---
* content
{:toc}

Aliun release** Qwen-TTS** Qwen-TTS High-performance speech synthesis modelText-to-Speech TTSI'm sorry, I don't know.Its core capability is to convert imported Chinese and English text into a voice output with natural expression powerI don't know.
And tradition. TTS Compared to model Qwen-TTS The big bright spot is...-

- **High Nature**High Nature-The voice is closer to the real person. With emotions.RhythmChange of tone;

- **Multilingual and dialect support**Multilingual and dialect support-Current support for MandarinEnglish And three Chinese dialects.BeijingShanghaiSichuan);

- **Multisound Selection**Multisound Selection-Provision of gender-specificVoice and accent Fit to diversity scenesI don't know.


### Details of language and dialect support
Supported speech variants-
![](https://assets-v2.circle.so/v74cwxkerya07wp34scg5vav90zg)Real Synthetic Samples-**https://qwenlm.github.io/zh/blog/qwen-tts/**https://qwenlm.github.io/zh/blog/qwen-tts/

### Technical rationale and data base
1. Large-scale training materials support
Model training was used**More than 300 A million hours.**More than 300 A million hours.Voice data Includes data on the alignment of Chinese and English, and a wealth of dialectic material This makes the model not only sound natural. And it mimics the way people talk in different places.I don't know.
2. Rhythm and Emotional Modelling
Qwen-TTS Support**Automatically adjust the speed of textHeavinessRhythm and emotional performance**Automatically adjust the speed of textHeavinessRhythm and emotional performanceI don't know.For example... It's a surprise.When you're gentle or angry. The voice automatically reflects the emotions. You don't have to make it out loud.I don't know.
3. Audio Modelling and Style Migration

- The model is passed.“At the end of the day,Audio EncodingIt's not a good idea, it's not a good idea.Technology So that the same sentence can produce a variety of styles.It's like a man's voice./Woman.Northern accent/Southern accentI'm not sure what I'm talking about.Voice outputI don't know.

- Current support **7 Sound**7 Sound-
CherryEthanChelsieSerenaChinese EnglishI'm not sure what I'm talking about.

- DylanBeijing.JadaShanghai.SunnySichuanI'm not sure what I'm talking about.

### Performance assessment-
![](https://assets-v2.circle.so/r1q7s630kk5h6p1u7n2cecv4faf3)♪ MODEL IN ♪ **SeedTTS-Eval**SeedTTS-Eval The indicators in the evaluation are as follows:-
Core indicators-

- **WERWord error rateI'm not sure what I'm talking about.**WERWord error rateI'm not sure what I'm talking about.-Accuracy of voice recognition echo text The lower the better.;

- **SIMSound SimilarityI'm not sure what I'm talking about.**SIMSound SimilarityI'm not sure what I'm talking about.-Measuring the level of sound-generation proximity to target-sounding The higher the better.I don't know.

### How do you use it?-API Access to the code
**Prices-**Prices-
![](https://assets-v2.circle.so/lqxd9zgzsxkmqxw1db1vffmssr0n)Qwen-TTS Pass. Qwen API It's a way to make it available. Users can use the following Python Example call model to complete speech synthesis task-
Basic processes-
Set API KeyDashScope API);
Set Synthetic StatementTarget sound color and model version;
Call Synthetic Functions Get Audio Links;
Download and save audio filesI don't know.
Example SnippetSimplified:
import os
import requests
import dashscope
def get_api_key():
api_key = os.getenv("DASHSCOPE_API_KEY")
if not api_key:
raise EnvironmentError("DASHSCOPE_API_KEY environment variable not set.")
return api_key
def synthesize_speech(text, voice="Dylan", model="qwen-tts-latest"):
api_key = get_api_key()
try:
response = dashscope.audio.qwen_tts.SpeechSynthesizer.call(
model=model,
api_key=api_key,
text=text,
voice=voice,
)
# Check if response is None
if response is None:
raise RuntimeError("API call returned None response")
# Check if response.output is None
if response.output is None:
raise RuntimeError("API call failed: response.output is None")
# Check if response.output.audio exists
if not hasattr(response.output, 'audio') or response.output.audio is None:
raise RuntimeError("API call failed: response.output.audio is None or missing")
audio_url = response.output.audio["url"]
return audio_url
except Exception as e:
raise RuntimeError(f"Speech synthesis failed: {e}")
def download_audio(audio_url, save_path):
try:
resp = requests.get(audio_url, timeout=10)
resp.raise_for_status()
with open(save_path, 'wb') as f:
f.write(resp.content)
print(f"Audio file saved to: {save_path}")
except Exception as e:
raise RuntimeError(f"Download failed: {e}")
def main():
text = (
"""Yo, yo. Guess what?Let me see it today.NBA Curly's pitching like he's playing around. I'll be right there. He's got to be called in the basket.“At the end of the day,Father.It's not a good idea, it's not a good idea.Yeah."""
)
save_path = "downloaded_audio.wav"
try:
audio_url = synthesize_speech(text)
download_audio(audio_url, save_path)
except Exception as e:
print(e)
if __name__ == "__main__":
main()
