---
layout: post
title: GoogleRelease Gemma 3n-A new generation of lightweight multimodules. AI Model Respond speed up the contract. 1.5 Multiply 2GBMemory cell phones are running.
date: 2025-06-15 12:00:00 +0800
category: Frontier Trends
thumbnail: /style/image/google-gemma-3n-ai-1-5-2gb_1.jpg
icon: link
---
* content
{:toc}

**Gemma 3n**Gemma 3n (")nIt's not a good idea, it's not a good idea.Meaning Nano or Next-genI'm not sure what I'm talking about.Yes. Google Newly launched lightweight open source AI Model Aim at achieving“At the end of the day,**Device Local Runon-deviceI'm not sure what I'm talking about.+ Multimodular Perceptions + Efficient and low delays**Device Local Runon-deviceI'm not sure what I'm talking about.+ Multimodular Perceptions + Efficient and low delaysIt's not a good idea, it's not a good idea.Three objectives.I don't know.
It's going on. Gemma 3 SeriesSupport desktop/The cloud's reasoning.I'm not sure what I'm talking about.Behind**First preview of model architecture optimized for mobile devices**First preview of model architecture optimized for mobile devices And it's the next generation. **Gemini Nano Series Model**Gemini Nano Series Model Technical basisI don't know.

- Parameter Size-5B and 8BWe'll split up.50100 million and80Billion parametersI'm not sure what I'm talking about.

- Support Model-TextImageAudioVoice recognition and translation.VideoWe're about to open.I'm not sure what I'm talking about.

![](https://assets-v2.circle.so/hnczcohntm5qbb9qlgsrlcbwgcln)
## Core Bright Point FunctionCompatibility of performanceEfficiency and privacyI'm not sure what I'm talking about.

### ✅ 1. Extremely light and quick response

- **Respond speed up the contract. 1.5 Multiply**Respond speed up the contract. 1.5 MultiplyContrast Gemma 3 4BThis is the first time I've ever seen you.At the high end Android It's on the phone.<500ms Postponement of the first wordI don't know.

- Beneficiary. DeepMind It's innovative. **Per-Layer EmbeddingsPLEI'm not sure what I'm talking about.**Per-Layer EmbeddingsPLEI'm not sure what I'm talking about. Technology Memory occupancy has been significantly reduced;
Although model parameters are-
5B50BillionsI'm not sure what I'm talking about. and 8B80Billions);

The memory required when actually running is only-

- **~2GB5BModelI'm not sure what I'm talking about.**~2GB5BModelI'm not sure what I'm talking about.

- **~3GB8BModelI'm not sure what I'm talking about.**~3GB8BModelI'm not sure what I'm talking about.

That means...-**Centre Android Cell phones can also run large models of reasoning.**Centre Android Cell phones can also run large models of reasoning. Don't need cloud support.I don't know.
Fitness QualcommMediaTekSamsung Waiting for mobile hardware platformsI don't know.

### ⚙️ 2. Dynamic adjustable model structureMix'n'Match StructureI'm not sure what I'm talking about.
“At the end of the day,**MixnMatch**MixnMatchIt's not a good idea, it's not a good idea. Structure 5B Models automatically switch to embedded ones. 2B Submodel;

- There's an embedded submodel embedded in the model structure.2B Active memory model embedded in 4B in the main modelThis is the first time I've ever seen you.Developer can**Dynamic adjustment accuracy and reasoning speed**Dynamic adjustment accuracy and reasoning speed Adapting to different use scenarios;

- Balance between accuracy and speed, depending on equipment capacity or user needs dynamically;

- This architecture is achievable.“At the end of the day,One model covers multiple scenes.It's not a good idea, it's not a good idea.

- You've done a great job in power control. Specially suitable for battery-sensitive equipmentCell phone.Glasses.HeadphonesEdge DeviceI'm sorry, I don't know.

### 🛡️ 3. Completely Local Run Privacy priority

- You don't have to network to run a reasoned task.;

- All data processed on the device Don't pass the clouds. Guaranteeing user privacy;

- It's for cell phones.Notebook.Edge devices, etc.I don't know.

## Multi-module capacity enhancement
Gemma 3n Right now. Google Most advanced.**Move one of the open source models of multimodule end**Move one of the open source models of multimodule end Its scope of support includes:-
![](https://assets-v2.circle.so/cpksy3sc0xplnt493agu9jpuq523)
## Model uses-To build the next generation.“At the end of the day,Walking intelligence experience.It's not a good idea, it's not a good idea.
📱 Expected application scenario
![](https://assets-v2.circle.so/g7c93o6x5jnbec10e85xlig94a8f)
## How's it going?
📊**Natural language missions**Natural language missions
Google ♪ Called its model ♪ Chatbot Arena Showing in rows“At the end of the day,TopI'm not sure what I'm going to do.In user preference rating-

- It's like a mainstream open source model. **Mistral 7BPhi-3LLaMA 3**Mistral 7BPhi-3LLaMA 3;

- Stabilized in bilingual Chinese and English missions Especially when dealing with it.**Multi-round dialogueLong Text GenerationLogical Questions and Answers**Multi-round dialogueLong Text GenerationLogical Questions and AnswersAspectsI don't know.

🌐 Multilingual performance-

- It's in multiple languages. benchmarkLike **WMT24++**WMT24++, ChrFI'm not sure what I'm talking about.Score **50.1%**50.1%;

- Yes. **JapaneseGermanKoreanFrenchSpanish**JapaneseGermanKoreanFrenchSpanish You've done a great job waiting for a language mission.;

- This suggests that it is superior to many Western-led models in terms of the adaptability of international markets.I don't know.

![](https://assets-v2.circle.so/q3gqwbs882gpmx3zb9py5cjm05n7)**Compared to the same model**Compared to the same model
![](https://assets-v2.circle.so/m7wgcgosr55t605rfggtwzbn1x93)
## Core technical detail
Gemma 3n One of the key technological highlights**Significant reduction in memory occupancy while running**Significant reduction in memory occupancy while running Achieved in three ways:-

### 1️⃣ Per-Layer EmbeddingPLEI'm not sure what I'm talking about.

- **What is it?**What is it?-It's a kind of cause. Google DeepMind New embedded strategies proposed;

- **Role**Role-Each layer uses an independent low-dimensional embedding vector instead of full model sharing embedding Table;

- **Advantages**Advantages-
Reduce Memory Copy;

- Better condensed expression space;

- Support loading on demandlazy loading);

**Effect**Effect-Ambassador 5B / 8B The dynamic running memory of the parameter model is reduced to **- I'm sorry. - I'm sorry. 2GB / 3GB**- I'm sorry. - I'm sorry. 2GB / 3GB;

- It's kind of like a big model.“At the end of the day,Fake.It's not a good idea, it's not a good idea.Make it one. 2B or 4B A lightweight version to runI don't know.

### 2️⃣ Key-Value Cache SharingKVC SharingI'm not sure what I'm talking about.

- **What is it?**What is it?-Transformer Models need to store intermediate results of attention mechanisms when reasoningKey and Value);

- **Role**Role-Share this cache on multiple layers or steps Reduction of double counting and memory redundancies;

- **Advantages**Advantages-
Reducing the cost of reasoning memory;

- Speed up sequence generation. Increase the multi-round interactive experience.I don't know.

### 3️⃣ Advanced Activation QuantizationAAQI'm not sure what I'm talking about.

- **What is it?**What is it?-Quantification of intermediate activation valuesFrom, for example, float32 Down to int8 or int4);

- **Role**Role-Significant reduction of model computing and memory bandwidth requirements;

- **Advantages**Advantages-
Keep model accuracy while reducing volume;

- Support models are moving chips.QualcommMediaTekI'm not sure what I'm talking about.Go up and run efficiently.;

- and PLEKVC Joint use Can be further compressed to acceptable levels for mobile devicesI don't know.

### Mixed architecture design-MixnMatch Mechanisms
**🧩 “At the end of the day,A set of models. Multiple capabilitiesIt's not a good idea, it's not a good idea.**🧩 “At the end of the day,A set of models. Multiple capabilitiesIt's not a good idea, it's not a good idea.
Gemma 3n Internal passage **MatFormer Training strategy**MatFormer Training strategy A mosaic model mechanism has been achieved.-
Model structure function description of the main modelLike 4BI'm not sure what I'm talking about.Submodels with high-precision reasoning abilitiesLike 2BI'm not sure what I'm talking about.Performance LightnessRespond to rapid dynamic switching according to mission complexityAuto-selection of running path sub-models for device resources to inherit sub-model weights shared by the main model Avoidance of deployment
This structure has the following advantages:-

- Developers do not need to deploy multiple model versions;

- Trade-off between dynamic reconciliation quality and delay at runningLike-Navigation Assistant vs Semantic translation);

- Enhancing energy consumption control capabilities Fit to high-end low-end equipmentI don't know.

![](https://assets-v2.circle.so/feusty2yr9s1s7qcz5dzvsw6tmy9)
## How? Gemma 3n
Google Opened two ways It's for different groups of people.-
Mode one.-**AI StudioWeb versionI'm not sure what I'm talking about.**AI StudioWeb versionI'm not sure what I'm talking about.

- Do not install Experience model text interpretation and generation directly in the browser;

- Suitable for product managersDeveloper Preview Model EffectsI don't know.

👉 Address-Google AI StudioYes. Google AccountI'm not sure what I'm talking about.
Mode two-**Google AI Edge**Google AI Edge**Local Development ToolI'm not sure what I'm talking about.**Local Development ToolI'm not sure what I'm talking about.

- Suitable developers want to integrate models. APPLocal systemsHardware equipment;

- Provision SDKDocumentCode Example Support text and image model deployment;

- Support AndroidChromeEmbedded devices, etc.I don't know.

### Detailed presentation-
Official presentation-https://developers.googleblog.com/en/introducing-gemma-3n/
