---
layout: post
title: Bland AI TTS Engine-Using a large language model to directly generate a voice that only needs a short audio to clone any human voice.
date: 2025-06-15 12:00:00 +0800
category: Frontier Trends
thumbnail: /style/image/bland-ai-tts_1.jpg
icon: image
---
* content
{:toc}

**Bland AI released a brand-new **Bland TTS, declaring it to be **the first “Uncanny Valley” product.**

- **Treasure Valley**: It means that AI's voice or face is not perfect when it's not perfect. Bland TTS claims it's broken, making AI's voice ** almost impossible to distinguish from the real person**.

Bland TTS** only requires a short audio ** to:

- Cloning any human voice.

- Or “combined” the other cloned voice style (e.g. tone, rhythm, pronunciation, etc.).

At its core is the use of large language models (LLMs) for direct voice generation, rather than relying on traditional layer-by-storey structures. The system has unprecedented emotional expression, style control, multi-talker understanding, non-verbal sound generation, and has achieved more real, controlled, and contextualized speech synthesis through self-researched audio Token systems (SNACs).

# Activate bright

#1 Style Transfer

- Models can be understood automatically through ** "Learning in context"** what is an "excited tone" or "cool tone";

- You can also manually add control labels such as: <excised>, which is a major breakthrough! <calm>. Read the following instructions carefully. - Only 3-6 speech examples are needed to enable the system to synthesize new content of the same style.

#2  sound generation not only synthesizing language but also ** producing sound ** e.g. <dog_bark> simulates laughter on behalf of dogs <lughter> if you provide annotated text and audio examples, the model will remember the correspondence.

#3 #VoiceBlending allows the system to automatically “combin” a new voice by providing multiple voice examples, preserving the characteristics of multiple interlocutors and maintaining a consistent tone.

- Brand voice design;

- Unanimous multilingual output;

- Virtual image role creation.

# # 4 # # Emotionally Aware is no longer a word-for-word system, but really changes the tone from context to context #

- More rational technical orientation;

- Comfortable content is warmer;

- Questions and answers are more natural.

# Core technology: Reconstructing the traditional TTS process ** The pains of the traditional TTS** The former TTS were the steps of the flow line: Text  Sound  Rhythm  Wave  Synthetic sound  Every step can be wrong and often the end effect is “lack of emotion, sound splitting.” This is because the traditional method** is to understand the content and then “combin” the voice** and it is very difficult to transmit the tone and emotions naturally. ** **  Bland: Integrated Model** Bland AI's new technology to enable the entire process to be achieved using ** Large Language Models to predict the sound directly ** the process: Text Input  Model outputs directly from Audio Token  and then to actually sound as if “You tell it what to say, it directly uses the language and emotions that understand it to produce a voice”, rather than a collator to “translify”.

##  breakthrough at the data level: a thousand-fold upgrade at the bottom of any generation system is data quality. The Bland team believes that open voice data is far from useful, especially in real dialogue modelling. They build a ** industry-top large-scale voice data set** with the following characteristics: [] [https://assets-v2.circle.so/ b3zzwwxqduz6nfhx1fgvjxgxrq]# technology architecture core: from text LLM to voice LLM

The traditional LLM approach is to split text into Token  the method of predicting the next Token  to restore it to full sentence Bland  predicting the corresponding "audio Token" to voice wave form **" Audio Token"** is a discrete expression encoded by SNAC (spectrally integrated audio encoder), taking into account:

- Macro beats (e.g. speed of speech, pause);

- Micro-details (e.g. pronunciation, sounds).

This approach allows the model to really master the “content plus expression” at the same time, right and right.

# **Application scene and user population**

# 1. Creatives

- Turn text into a real AI voice or sound**

- Support** fine control styles and emotions**

- Design scenes suitable for content such as podcasting, audio programming, audio novels, films, etc.

#2. # Developers

- Access your application via API

- Products used to construct custom voice functions (e.g. voice assistants, educational products, broadcasting systems, etc.)

##3. # Enterprise users

- Construction of commercial voice services such as **AI customer service systems, telephone assistants, etc.**

- The sound is natural. The client will even keep it as a contact.

- A dialogue with AI can be tried directly on the website**

Official introduction: https://www.bland.ai/blogs/new-tts-announcement Quick Start Link:

- Developer portal: https://t.co/qBpGkJh2Gp

- Enterprise portal: https://t.co/Szf9KNwfHs

