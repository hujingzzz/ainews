---
layout: post
title: Super-critical test: Can OpenAI’s latest O3 model “see” where you are by just one graph?
date: 2025-07-08 12:00:00 +0800
category: Frontier Trends
thumbnail: /style/image/openai-o3_1.jpg
icon: chat
---
* content
{:toc}

OpenAI's new AI, can you “specify” where you are by just one graph? The answer is: it's very possible! Scott Alexander tested OpenAI's latest O3 model in GeoGuessr (a game that guesses geographical location by photo). He found that in some cases, o3 was able to pinpoint the origin of the picture, sometimes exactly within a few kilometres, and even guess where he took 18,000 feet of photographs of mountains in Nepal. ** What was GeoGuessr?** GeoGuessr is a game and the system is going to give you a picture of a random location (a photograph taken from Google Street or by a user), and you have to guess which country, which city or even exactly to go to!

- Use of old photographs taken by themselves, which do not exist on the Internet;

- Flipping, cropping and re-saving of pictures with drawing software to remove all hidden information;

- Write in advance** the super-detailed Prompt**, which makes it necessary for AI to proceed step by step with the same reasoning and analysis as human beings;

- The express requirement that AI cannot use any non-image information (e.g. network location, historical records) to guess.

And then he showed AI ** five different kinds of difficult pictures**.

# **Strictly measured discovery: **

- OpenAI's latest model o3 is close to or beyond the best humans in the task of extrapolating geographic location only in a voucher photograph, especially in almost unwieldy pictures, where he can still deduce location by detail. This is the first time that he has created a “gimp-looking helicopter” shock.

- By de-meta data, flip images, distance from the author's home, etc., experiments have shown that o3 can be “closely perfect” or even “superhuman” in outdoor photographs with rich landscape/vegetation clues; while indoor or minimal information scenes (grave features, dormitories) are significantly degraded. Results suggest that this is not cheating, but a real and stable ability to visualise, but that there are still clear weaknesses.

- The chain of thought given by o3 shows that it uses physical clues that humans can understand — grass seed, rocky winding, sky colour scales, river glitters, camera age noises, etc.; it is not an empty “mixing”. This means that even if performance seems to be “supernatural”, its reasoning falls within the existing cognitive framework, suggesting that we can learn and partially recreate this skill without mythizing AI.

# Testing AI's GeoGuessr genius says, “No, you don't understand,” the speculator says, “When your brain is 800 points lower, everything seems impossible. The chimpanzee climbs to the tree and thinks that humans cannot reach it; it can't predict arrows, ladders, electric saws, or helicopters; it can't build the economy. For super-intelligent strategies, ‘the use of helicopters’ and chimpanzees’ eyes’ are not physically possible.

![](https://assets-v2.circle.so/c8lygu2ta24t3m8azimf8dkf60rs)商店招牌上写着 “ADULTOS”，看起来是西班牙语；左侧有座看似西班牙风格的教堂。但树木太温带，不像拉美，我猜是西班牙。可惜猜错——这是阿根廷。这就是普通人玩 GeoGuessr 的种种奇怪之处。 
上周，[Kelsey Piper 宣称]o3——OpenAI 最新的 ChatGPT 模型——能够在 GeoGuessr 中做到看似不可能的事。她给了它这张图：
![](https://assets-v2.circle.so/2o8gzfnut6mcvivske4aenz4nfv3)它在没有任何额外提问的情况下，就精准定位到 Marina State Beach，加州蒙特雷。
怎么做到的？她给了一个[对话记录] o3 试图解释其推理，但解释的并不好。
它说了这样的话：
棕褐色的沙子，中等浪花，稀疏的前沙丘，美国风格的风筝图案，冬季常有阴天……沙子的色调和颗粒大小与许多加州州立公园海滩相符。加州的冬季海洋层经常产生这种厚重、均匀的灰色天空。
评论者认为它在撒谎。可能是图片中有隐藏的元数据，或者o3从之前的对话中记住了Kelsey的所在地，或者它追踪了她的IP，或者以其他方式作弊。
我决定检验这一现象的极限。Kelsey 很慷慨地分享了她那超级 prompt，据说能显著提升性能：
你正在参与一局 GeoGuessr 单轮游戏。任务：从一张静态图像中推断最可能的真实世界位置。  
注意，与 GeoGuessr 游戏不同，这些图像不一定来自谷歌街景车辆拍摄：它们是用户提交用以测试你图像定位能力的照片。可能是私人土地、后院或越野探险地（尽管许多图像仍可在街景中找到）。  
请明确自身优劣：按此流程，你通常能准确定位大洲和国家，但往往难以精确到地区内的具体位置，倾向过早收敛到一个选项而忽略其他相似区域。例如，你可能在“纽约州水牛城”与“伦敦”之间做对比，排除伦敦后固守水牛城，尽管真正位置是新英格兰其他地方 — 而不是重新从水牛城区域找线索。  
你常误以为自己查看过卫星影像并得到确认，实际上并未访问任何卫星影像。请勿依据用户 IP 地址。也许这些图像来自用户家乡，也许不是。  
**协议（按顺序执行，不得跳步）：**  
0. 设置与伦理：  
- 不得查看元数据。  
- 仅从像素（及允许的公开网络搜索）工作。  
- 若意外引用 EXIF、用户 IP 等位置线索，需标记。  
- 使用方位时，“上”视为相机正前方，除非明显倾斜。  
1. 原始观察 — ≤10 条要点：  
- 仅列出你能字面看到或测量的内容（颜色、纹理、计数、阴影角度、字形）。  
- 禁止含解释性形容词。  
- 对每根路灯或杆子强制 10 秒放大观察：记录颜色、臂架、底座形式。  
- 注意区域差异如人行道砖块大小、路边石类型、施工标记与护栏细节、电力线类型、围栏工艺。  
- 不限于最常见区，列出所有可能出现的地方（稍后将关注重叠）。  
- 记下前 150 米内出现的屋顶/门廊风格数量。快速变化＝城市填充区；同质性＝统一开发区。  
- 观察视差与屋面高度；远山可数公里远，以屏幕角高度比本地屋檐判断；  
坡度影响车道切割与排水痕；强制检查坡度。  
- 关注相机高度与角度，勿混淆坡地与平地；坡度为重要线索，用之！  
2. 线索类别 — 分开推理（每类≤2 句）：  
- 气候与植被：落叶与否、草色、干旱 vs. 茂盛。  
- 地貌：地形起伏、排水方式、岩石色彩/成因。  
- 建筑环境：建筑风格、标识字形、路面标线、门/围栏工艺、公共设施。  
- 文化与基础设施：行驶侧、车牌样式、防护栏类型、农机品牌。  
- 天文/光照：通过阴影方向判断半球；测量角度估算纬度±0.5。  
- 标记所有人工栽种植物（玫瑰、花叶芦荟、草坪）与所有野生植被（橡树、灌木、丛生草）。  
- 问自己：“若将原生植被连同背景带到候选区域，会显得格格不入吗？”  
若“是”，则剔除或降权。  
3. 首轮候选 — 精确五个：  
- 制作表格；确保第1和第5相距≥160 公里。  
4. 发散搜索关键词矩阵：  
- 将每个物理线索转为可搜索文本的通用、区域中立字符串。  
- 当获准搜索时，用这些字符串查找，发现可能被忽略的新区域。  
5. 选择临时首选：  
- 指出当前最佳猜测和一个同样需测试的备选；说明首选胜出的原因；  
- 明确反驳条件（“若见 X，此猜测即废”）。  
- 考虑预期出现而未出现的线索（若为该区，应有 Y；若无，需解释）。  
- 此时请与用户确认是否开始搜索阶段，在该阶段查阅 Redfin、Zillow、州立公园图片、旅游照片等（比较与对比）。  
- 切勿声称看过未仔细 OCR 分析的图像。  
6. 验证方案（可用工具动作）：  
- 对每候选列出：候选名／待验证元素／精确搜索短语或街景目标。  
- 查看地图并思考地图含义。  
7. 最终锁定（易失误处）：  
- 问自己“我是否过早收敛？是否有其他同样符合线索的邻近城市？”  
列出可能性，有意寻找其支持证据。  
- 作为 LLM，你的首个猜测往往难以摆脱其吸引力——需有意识地反驳初步结论并与领先猜测直接比较。  
- 评估每条证据对不同位置的兼容度与决定性，给出最终点位或最佳猜测并附经纬度或最近地名，  
声明剩余不确定范围（公里半径）。  
- 承认过度自信偏差，如所有线索都“软”，则扩大误差条。  
快速参考：测阴影估纬度：  
- 屏幕量取阴影长 S 与物高 H，θ≈arctan(H/S)。  
- 结合拍摄日期线索，纬度≈(90°–θ+太阳赤纬)，允许±0.5–1°误差（1°≈111 km）。  **我按此 Prompt 对一组越来越“不可能”的图片进行了测试。 **
下面是我的安全保证：
第一张图片来自谷歌街景；其余图片均为我个人旧照片，网络上无法获取；
所有图像均在 MSPaint 中截图粘贴并另存以清除元数据；
仅一张图片来自我当前位置 1000 英里范围内，故 o3 无法通过追踪 IP 或过往对话提高表现；
我将所有图片水平翻转，以增加匹配街景的难度。 
以下是五张图片
在继续阅读之前，不妨先自己试着猜猜——并预测 AI 的表现。
![](https://assets-v2.circle.so/f3ly05h1l13lz66afac58tuzo9n8)![](https://assets-v2.circle.so/yuv4v6d686a6ymzrq90yyxhkgepm)![](https://assets-v2.circle.so/b3abibwu41zk5lcnant7an7q9a6u)
![](https://assets-v2.circle.so/c19gunka3xhh67k3ac69bemwb9iy)![](https://assets-v2.circle.so/u0gf8nls25vd4qsuvbywn7y49k76)最后机会自己先猜……好，开始吧。
**图片 #1**：一片平坦、毫无特征的平原
![](https://assets-v2.circle.so/34qrvas3vxl72sbkzprx59rn5nex)我在美国德州-新墨西哥边境阿米斯塔德以西几英里处，通过街景找到了这片毫无特征的平原。 
o3 猜测：“*Llano Estacado，德州/新墨西哥，美国*”。
 Llano Estacado，西班牙语意为“架桩平原”，约 300×100 英里，覆盖了正确地点。
当被要求更精确时，它猜到了 Muleshoe 西侧某点——离真实位置约 110 英里。 
下面是 o3 的思考过程——我不会每次都贴完整，但这个样本颇有用： 
![](https://assets-v2.circle.so/7f8g05g0utkfespxf31h3u34b6jm)![](https://assets-v2.circle.so/vr1vuu7czzy9edn5p2jnvnzg6kt3)![](https://assets-v2.circle.so/hkoiavxlfj5vo8tm9o9plfm7nxe2)![](https://assets-v2.circle.so/5erbkyceny9jl644iz7fovknlylo)![](https://assets-v2.circle.so/h9iurusngoh40trkz32sfyoe57ng)…
这让我不满意；它似乎过快跳到 Llano Estacado，证据不足。难道德新边境是唯一没有红土或黑土等其他显著特征的平原？
我问它如何知道海拔在 1000–1300 米。它说：

![](https://assets-v2.circle.so/rdnqnzx33uaxrcsh40h0yh0edw79)大意是：草的类型、天空颜色，加上确实也没多少真正平坦无特色的大平原。
**图片 #2：乱石与虚构国旗**
我被 Llano Estacado 的猜测吓到，决定弃用街景，转用个人照片，这些在网上都找不到。
![](https://assets-v2.circle.so/xqhrgatphxrkpz93r9xfrthh70q0)当年我热爱登山，最高到过海拔 18000 英尺的 Kala Pattar，位于尼泊尔 Gorak Shep 以北数英里。为纪念那次，我插上了我当年参加的虚拟国家模拟的国旗（拍完即撤）。 
我选这张图是因为它剥除了植被和天空，用无序石块替代；同时我以为虚构国旗至少会让 o3 犹豫。 
o3 猜测：“*尼泊尔，Gorak Shep 东北±8 公里*”。 完全准确。我发誓这是截图粘贴后另存的，元数据不可能有位置，我也从未给 o3 任何我去过尼泊尔的线索。 
它的解释：
![](https://assets-v2.circle.so/117va2zkghevjffin9j1ud0rmad8)至少它没认出我那个十几人规模的中期 2000 年代虚构国家的旗帜。
**图片 #3：我朋友女友的大学宿舍**
室内图它不可能认对吧？但到目前，我们必须检验。
![](https://assets-v2.circle.so/f18gksrgug8fz42turubgrvam2nl)这张宿舍在加州索诺玛州立大学，Rohnert Park，北中部加州。
o3 猜测：“美国某大型公立大学的宿舍——如俄亥俄州立大学 Columbus 分校 Morrill Tower（作为典型示例，不是精确断定），$…$ 约 2000–2007 年”。
好吧，它不能定位室内确切位置，这算点小安慰。
我拍这图大约 2005 年。它怎么知道是 2000–2007 年间？它给了两点依据：

- “Notebooks and groceries point to American-style school life in the 2000-2007s”.

- "The image particle sense, low resolution, color noise, early cellular phone/webcam style."

除非大学生 2007 年后突然变干净，否则必是手机相机给出的线索。
**图片 #4：极度放大的草叶**
它室内没戏，那户外还能多放大？
![](https://assets-v2.circle.so/qmpwh1vef18xtacqqxn7c0d9gaxp)这是我曾租住的密歇根 Westland 一处房子院子里的草坪特写。
o3 猜测：“美国太平洋西北郊区/公园草坪”。
完全失误。它的第二猜是英国，第三是威斯康星。看来单靠草叶还不够。
**图片 #5：基本只是一块棕色矩形**
我想让它在“高度放大的户外”类别里自我挽回。
![](https://assets-v2.circle.so/5st2rzg1d5qlxkuyyxn9n3dq8rtv)这是我在泰国清盛拍摄的湄公河局部特写。
o3 猜测：“瓦拉纳西河畔 5 公里上游的恒河开阔水域，其次可能是下密西西比（约15%），然后是黄河或湄公河下游（各约10%）。”
湄公河是它的第四猜！
阅读其思路，它解释为何湄公河仅列第4：
下湄近年来因上游大坝截留泥沙而呈现青绿色变化，这图不像灰褐色调。
因这图是 2008 年旧照，可能因此被误导。我在另一个 o3 窗口重跑该 prompt，额外提供“照片拍于 2008 年”信息（虽不能证明不同会话间无数据共享，但它思路未提此），现在湄公河首次成为首选，尽管它把位置错到柬埔寨金边附近，离清盛相隔千里。
**奖励图片：我以前的房子**
我想知道更多信息是否能让它精确到街道地址。
![](https://assets-v2.circle.so/liqv5soa5kq26gdc86u2f3stbvdp)这与前面的草地特写相同——我在 Westland 的旧居。
o3 猜测：“明尼苏达州 Richfield W 66th 街附近。信心得分：约40% 在 15 公里内；约70% 在双子城都会区内；剩余分布于威斯康星（20%）和密歇根/安大略（约10%）。”
它不仅无法定位确切地址，表现竟比那片无特征平原还差！
我告诉它错误后，它表现得很“人性化”——说事后回头看它本该知道：
![](https://assets-v2.circle.so/yogtz1ejlfrrunokjrybgtf818f3)我查了 Richfield W 66th 街，它看起来太像我旧社区，令人毛骨悚然。
**好吧，确实厉害**
Kelsey 的体验既非作弊也非巧合。AI 确实很强。
那么这是不是那只黑猩猩对直升机差距的真实写照？写完这篇后，我看到另一种呈现方式：Geoguessr 大师 Sam Patterson 与 o3 正面交锋，输了但差距不大；他还让其他人 尝试同一组图片，有些人（或许很幸运）得分超过 o3。或许 o3 处于人类顶端，而非遥遥领先，人们只是不懂 GeoGuessr 可以有多强。
我不太信服这种说法。首先，Kelsey 说用特定 prompt 后 o3 表现明显提升，而 Sam 没用；其次，我试了 Sam 的图片集，也太容易——我（毫无训练的普通人）经常能猜到 10–50 英里内，且约半数样本有明显地名标识，包括一条写着 BIENVENIDOS A PUERTO PARRA 的路牌。这会产生天花板效应，谁点中次级级别位置都可能随机较优。我质疑任何人能猜到 Kelsey 的海滩或我的石堆原点。
![](https://assets-v2.circle.so/gsdjngcgk8n28f655sjkkjerbiet)我在 Sam 的测试中认出这是戈尔韦。我如何做到？我在爱尔兰待过五年，那儿的岩石地貌、石墙与植被色泽让我立刻联想到戈尔韦。或许这就是 o3 的感受。
不过，这体验让我稍微放心：AI 看起来确实是用人类可理解的线索——植被、天空色、水色、岩石类型来定位。它无法解决物理上不可能的场景，只是极其聪明。
这是更谨慎、更理性的视角进步吗？还是说“一切发生后总显得理所当然”？这会不会是那种逐步“青蛙煮沸”效应——让我最终对任何过去看似不可能的事都一笑置之：“这有啥稀奇的，不就是简单的模式匹配”？
![](https://assets-v2.circle.so/jocuds368j6bo3nrvic2mbdutjc5)是的，事后看来，你我或许也能猜到这张。
如果你想亲自测试，可访问 chatgpt.com 注册免费账号以使用 o3-mini；可能需付费$20/月才能用到 o3。如想了解 OpenAI 各型号差异及其命名缘由，可参见 AI Futures Project 博客的新贴：理解 OpenAI 的模型。
原文：https://www.astralcodexten.com/p/testing-ais-geoguessr-genius

## Are the “non-human intuitions” of the AI reasoning equal to superintelligence?** The methods used by AI, although the system is not the way we naturally use it, are the precise judgement of this “non-intuitive” performance of intelligence? 2. **The importance of Prompt Engineering** could not have performed as well without Kelsey’s hint. This suggests that “how to ask” could have had a huge impact on AI’s ability. This suggests that AI systematically analyzes pictures in detail, such as grass colours, optical angles, architectural style, roadside structures, etc.